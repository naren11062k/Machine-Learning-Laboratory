{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import roc_curve\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pima = pd.read_csv(\"pima.csv\")\n",
    "pima = pima.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.000e+00, 1.410e+02, 5.800e+01, 3.400e+01, 1.280e+02, 2.540e+01,\n",
       "        6.990e-01, 2.400e+01],\n",
       "       [7.000e+00, 8.100e+01, 7.800e+01, 4.000e+01, 4.800e+01, 4.670e+01,\n",
       "        2.610e-01, 4.200e+01],\n",
       "       [1.300e+01, 1.060e+02, 7.200e+01, 5.400e+01, 0.000e+00, 3.660e+01,\n",
       "        1.780e-01, 4.500e+01],\n",
       "       [5.000e+00, 4.400e+01, 6.200e+01, 0.000e+00, 0.000e+00, 2.500e+01,\n",
       "        5.870e-01, 3.600e+01],\n",
       "       [8.000e+00, 1.830e+02, 6.400e+01, 0.000e+00, 0.000e+00, 2.330e+01,\n",
       "        6.720e-01, 3.200e+01],\n",
       "       [2.000e+00, 1.090e+02, 9.200e+01, 0.000e+00, 0.000e+00, 4.270e+01,\n",
       "        8.450e-01, 5.400e+01],\n",
       "       [1.100e+01, 1.380e+02, 7.600e+01, 0.000e+00, 0.000e+00, 3.320e+01,\n",
       "        4.200e-01, 3.500e+01],\n",
       "       [3.000e+00, 1.130e+02, 4.400e+01, 1.300e+01, 0.000e+00, 2.240e+01,\n",
       "        1.400e-01, 2.200e+01],\n",
       "       [1.000e+00, 1.220e+02, 9.000e+01, 5.100e+01, 2.200e+02, 4.970e+01,\n",
       "        3.250e-01, 3.100e+01],\n",
       "       [7.000e+00, 1.000e+02, 0.000e+00, 0.000e+00, 0.000e+00, 3.000e+01,\n",
       "        4.840e-01, 3.200e+01],\n",
       "       [5.000e+00, 1.170e+02, 9.200e+01, 0.000e+00, 0.000e+00, 3.410e+01,\n",
       "        3.370e-01, 3.800e+01],\n",
       "       [7.000e+00, 1.070e+02, 7.400e+01, 0.000e+00, 0.000e+00, 2.960e+01,\n",
       "        2.540e-01, 3.100e+01],\n",
       "       [2.000e+00, 1.000e+02, 6.800e+01, 2.500e+01, 7.100e+01, 3.850e+01,\n",
       "        3.240e-01, 2.600e+01],\n",
       "       [1.000e+01, 1.250e+02, 7.000e+01, 2.600e+01, 1.150e+02, 3.110e+01,\n",
       "        2.050e-01, 4.100e+01],\n",
       "       [1.000e+00, 0.000e+00, 4.800e+01, 2.000e+01, 0.000e+00, 2.470e+01,\n",
       "        1.400e-01, 2.200e+01],\n",
       "       [7.000e+00, 1.060e+02, 9.200e+01, 1.800e+01, 0.000e+00, 2.270e+01,\n",
       "        2.350e-01, 4.800e+01],\n",
       "       [8.000e+00, 9.900e+01, 8.400e+01, 0.000e+00, 0.000e+00, 3.540e+01,\n",
       "        3.880e-01, 5.000e+01],\n",
       "       [2.000e+00, 9.000e+01, 6.800e+01, 4.200e+01, 0.000e+00, 3.820e+01,\n",
       "        5.030e-01, 2.700e+01],\n",
       "       [1.000e+00, 1.460e+02, 5.600e+01, 0.000e+00, 0.000e+00, 2.970e+01,\n",
       "        5.640e-01, 2.900e+01],\n",
       "       [3.000e+00, 8.800e+01, 5.800e+01, 1.100e+01, 5.400e+01, 2.480e+01,\n",
       "        2.670e-01, 2.200e+01],\n",
       "       [1.000e+00, 1.890e+02, 6.000e+01, 2.300e+01, 8.460e+02, 3.010e+01,\n",
       "        3.980e-01, 5.900e+01],\n",
       "       [4.000e+00, 1.230e+02, 8.000e+01, 1.500e+01, 1.760e+02, 3.200e+01,\n",
       "        4.430e-01, 3.400e+01],\n",
       "       [0.000e+00, 1.800e+02, 6.600e+01, 3.900e+01, 0.000e+00, 4.200e+01,\n",
       "        1.893e+00, 2.500e+01],\n",
       "       [1.000e+00, 1.030e+02, 8.000e+01, 1.100e+01, 8.200e+01, 1.940e+01,\n",
       "        4.910e-01, 2.200e+01],\n",
       "       [5.000e+00, 1.660e+02, 7.200e+01, 1.900e+01, 1.750e+02, 2.580e+01,\n",
       "        5.870e-01, 5.100e+01],\n",
       "       [9.000e+00, 1.710e+02, 1.100e+02, 2.400e+01, 2.400e+02, 4.540e+01,\n",
       "        7.210e-01, 5.400e+01],\n",
       "       [0.000e+00, 1.180e+02, 8.400e+01, 4.700e+01, 2.300e+02, 4.580e+01,\n",
       "        5.510e-01, 3.100e+01],\n",
       "       [0.000e+00, 1.050e+02, 6.400e+01, 4.100e+01, 1.420e+02, 4.150e+01,\n",
       "        1.730e-01, 2.200e+01],\n",
       "       [7.000e+00, 1.960e+02, 9.000e+01, 0.000e+00, 0.000e+00, 3.980e+01,\n",
       "        4.510e-01, 4.100e+01],\n",
       "       [0.000e+00, 1.460e+02, 8.200e+01, 0.000e+00, 0.000e+00, 4.050e+01,\n",
       "        1.781e+00, 4.400e+01],\n",
       "       [4.000e+00, 1.340e+02, 7.200e+01, 0.000e+00, 0.000e+00, 2.380e+01,\n",
       "        2.770e-01, 6.000e+01],\n",
       "       [5.000e+00, 9.500e+01, 7.200e+01, 3.300e+01, 0.000e+00, 3.770e+01,\n",
       "        3.700e-01, 2.700e+01],\n",
       "       [1.000e+01, 1.680e+02, 7.400e+01, 0.000e+00, 0.000e+00, 3.800e+01,\n",
       "        5.370e-01, 3.400e+01],\n",
       "       [3.000e+00, 1.800e+02, 6.400e+01, 2.500e+01, 7.000e+01, 3.400e+01,\n",
       "        2.710e-01, 2.600e+01],\n",
       "       [7.000e+00, 8.300e+01, 7.800e+01, 2.600e+01, 7.100e+01, 2.930e+01,\n",
       "        7.670e-01, 3.600e+01],\n",
       "       [5.000e+00, 1.090e+02, 7.500e+01, 2.600e+01, 0.000e+00, 3.600e+01,\n",
       "        5.460e-01, 6.000e+01],\n",
       "       [1.300e+01, 1.260e+02, 9.000e+01, 0.000e+00, 0.000e+00, 4.340e+01,\n",
       "        5.830e-01, 4.200e+01],\n",
       "       [1.000e+00, 7.900e+01, 7.500e+01, 3.000e+01, 0.000e+00, 3.200e+01,\n",
       "        3.960e-01, 2.200e+01],\n",
       "       [3.000e+00, 1.580e+02, 7.600e+01, 3.600e+01, 2.450e+02, 3.160e+01,\n",
       "        8.510e-01, 2.800e+01],\n",
       "       [0.000e+00, 1.310e+02, 0.000e+00, 0.000e+00, 0.000e+00, 4.320e+01,\n",
       "        2.700e-01, 2.600e+01],\n",
       "       [1.000e+00, 1.030e+02, 3.000e+01, 3.800e+01, 8.300e+01, 4.330e+01,\n",
       "        1.830e-01, 3.300e+01],\n",
       "       [6.000e+00, 9.300e+01, 5.000e+01, 3.000e+01, 6.400e+01, 2.870e+01,\n",
       "        3.560e-01, 2.300e+01],\n",
       "       [7.000e+00, 1.870e+02, 6.800e+01, 3.900e+01, 3.040e+02, 3.770e+01,\n",
       "        2.540e-01, 4.100e+01],\n",
       "       [1.000e+00, 1.070e+02, 6.800e+01, 1.900e+01, 0.000e+00, 2.650e+01,\n",
       "        1.650e-01, 2.400e+01],\n",
       "       [1.100e+01, 1.430e+02, 9.400e+01, 3.300e+01, 1.460e+02, 3.660e+01,\n",
       "        2.540e-01, 5.100e+01],\n",
       "       [0.000e+00, 1.010e+02, 6.500e+01, 2.800e+01, 0.000e+00, 2.460e+01,\n",
       "        2.370e-01, 2.200e+01],\n",
       "       [1.000e+00, 8.000e+01, 5.500e+01, 0.000e+00, 0.000e+00, 1.910e+01,\n",
       "        2.580e-01, 2.100e+01],\n",
       "       [6.000e+00, 1.480e+02, 7.200e+01, 3.500e+01, 0.000e+00, 3.360e+01,\n",
       "        6.270e-01, 5.000e+01],\n",
       "       [4.000e+00, 1.110e+02, 7.200e+01, 4.700e+01, 2.070e+02, 3.710e+01,\n",
       "        1.390e+00, 5.600e+01],\n",
       "       [1.000e+00, 7.100e+01, 4.800e+01, 1.800e+01, 7.600e+01, 2.040e+01,\n",
       "        3.230e-01, 2.200e+01],\n",
       "       [7.000e+00, 6.200e+01, 7.800e+01, 0.000e+00, 0.000e+00, 3.260e+01,\n",
       "        3.910e-01, 4.100e+01],\n",
       "       [0.000e+00, 1.090e+02, 8.800e+01, 3.000e+01, 0.000e+00, 3.250e+01,\n",
       "        8.550e-01, 3.800e+01],\n",
       "       [1.000e+01, 1.220e+02, 7.800e+01, 3.100e+01, 0.000e+00, 2.760e+01,\n",
       "        5.120e-01, 4.500e+01],\n",
       "       [2.000e+00, 1.970e+02, 7.000e+01, 4.500e+01, 5.430e+02, 3.050e+01,\n",
       "        1.580e-01, 5.300e+01],\n",
       "       [2.000e+00, 9.200e+01, 6.200e+01, 2.800e+01, 0.000e+00, 3.160e+01,\n",
       "        1.300e-01, 2.400e+01],\n",
       "       [8.000e+00, 1.250e+02, 9.600e+01, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        2.320e-01, 5.400e+01],\n",
       "       [7.000e+00, 1.140e+02, 6.600e+01, 0.000e+00, 0.000e+00, 3.280e+01,\n",
       "        2.580e-01, 4.200e+01],\n",
       "       [1.300e+01, 1.450e+02, 8.200e+01, 1.900e+01, 1.100e+02, 2.220e+01,\n",
       "        2.450e-01, 5.700e+01],\n",
       "       [5.000e+00, 1.370e+02, 1.080e+02, 0.000e+00, 0.000e+00, 4.880e+01,\n",
       "        2.270e-01, 3.700e+01],\n",
       "       [1.000e+00, 9.700e+01, 6.600e+01, 1.500e+01, 1.400e+02, 2.320e+01,\n",
       "        4.870e-01, 2.200e+01],\n",
       "       [6.000e+00, 1.440e+02, 7.200e+01, 2.700e+01, 2.280e+02, 3.390e+01,\n",
       "        2.550e-01, 4.000e+01],\n",
       "       [9.000e+00, 1.190e+02, 8.000e+01, 3.500e+01, 0.000e+00, 2.900e+01,\n",
       "        2.630e-01, 2.900e+01],\n",
       "       [2.000e+00, 1.000e+02, 6.600e+01, 2.000e+01, 9.000e+01, 3.290e+01,\n",
       "        8.670e-01, 2.800e+01],\n",
       "       [1.000e+01, 1.390e+02, 8.000e+01, 0.000e+00, 0.000e+00, 2.710e+01,\n",
       "        1.441e+00, 5.700e+01],\n",
       "       [4.000e+00, 1.030e+02, 6.000e+01, 3.300e+01, 1.920e+02, 2.400e+01,\n",
       "        9.660e-01, 3.300e+01],\n",
       "       [3.000e+00, 1.260e+02, 8.800e+01, 4.100e+01, 2.350e+02, 3.930e+01,\n",
       "        7.040e-01, 2.700e+01],\n",
       "       [8.000e+00, 1.760e+02, 9.000e+01, 3.400e+01, 3.000e+02, 3.370e+01,\n",
       "        4.670e-01, 5.800e+01],\n",
       "       [5.000e+00, 1.390e+02, 6.400e+01, 3.500e+01, 1.400e+02, 2.860e+01,\n",
       "        4.110e-01, 2.600e+01],\n",
       "       [2.000e+00, 1.120e+02, 6.600e+01, 2.200e+01, 0.000e+00, 2.500e+01,\n",
       "        3.070e-01, 2.400e+01],\n",
       "       [7.000e+00, 1.050e+02, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        3.050e-01, 2.400e+01],\n",
       "       [4.000e+00, 1.100e+02, 9.200e+01, 0.000e+00, 0.000e+00, 3.760e+01,\n",
       "        1.910e-01, 3.000e+01],\n",
       "       [7.000e+00, 1.590e+02, 6.400e+01, 0.000e+00, 0.000e+00, 2.740e+01,\n",
       "        2.940e-01, 4.000e+01],\n",
       "       [1.500e+01, 1.360e+02, 7.000e+01, 3.200e+01, 1.100e+02, 3.710e+01,\n",
       "        1.530e-01, 4.300e+01],\n",
       "       [7.000e+00, 1.500e+02, 6.600e+01, 4.200e+01, 3.420e+02, 3.470e+01,\n",
       "        7.180e-01, 4.200e+01],\n",
       "       [1.000e+00, 1.150e+02, 7.000e+01, 3.000e+01, 9.600e+01, 3.460e+01,\n",
       "        5.290e-01, 3.200e+01],\n",
       "       [5.000e+00, 1.160e+02, 7.400e+01, 0.000e+00, 0.000e+00, 2.560e+01,\n",
       "        2.010e-01, 3.000e+01],\n",
       "       [1.000e+00, 7.300e+01, 5.000e+01, 1.000e+01, 0.000e+00, 2.300e+01,\n",
       "        2.480e-01, 2.100e+01],\n",
       "       [2.000e+00, 7.400e+01, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        1.020e-01, 2.200e+01],\n",
       "       [0.000e+00, 1.000e+02, 8.800e+01, 6.000e+01, 1.100e+02, 4.680e+01,\n",
       "        9.620e-01, 3.100e+01],\n",
       "       [2.000e+00, 1.420e+02, 8.200e+01, 1.800e+01, 6.400e+01, 2.470e+01,\n",
       "        7.610e-01, 2.100e+01],\n",
       "       [0.000e+00, 1.370e+02, 4.000e+01, 3.500e+01, 1.680e+02, 4.310e+01,\n",
       "        2.288e+00, 3.300e+01],\n",
       "       [2.000e+00, 7.100e+01, 7.000e+01, 2.700e+01, 0.000e+00, 2.800e+01,\n",
       "        5.860e-01, 2.200e+01],\n",
       "       [7.000e+00, 1.330e+02, 8.400e+01, 0.000e+00, 0.000e+00, 4.020e+01,\n",
       "        6.960e-01, 3.700e+01],\n",
       "       [7.000e+00, 1.470e+02, 7.600e+01, 0.000e+00, 0.000e+00, 3.940e+01,\n",
       "        2.570e-01, 4.300e+01],\n",
       "       [1.000e+00, 8.500e+01, 6.600e+01, 2.900e+01, 0.000e+00, 2.660e+01,\n",
       "        3.510e-01, 3.100e+01],\n",
       "       [7.000e+00, 1.030e+02, 6.600e+01, 3.200e+01, 0.000e+00, 3.910e+01,\n",
       "        3.440e-01, 3.100e+01],\n",
       "       [5.000e+00, 9.900e+01, 7.400e+01, 2.700e+01, 0.000e+00, 2.900e+01,\n",
       "        2.030e-01, 3.200e+01],\n",
       "       [4.000e+00, 1.290e+02, 8.600e+01, 2.000e+01, 2.700e+02, 3.510e+01,\n",
       "        2.310e-01, 2.300e+01],\n",
       "       [1.000e+00, 1.010e+02, 5.000e+01, 1.500e+01, 3.600e+01, 2.420e+01,\n",
       "        5.260e-01, 2.600e+01],\n",
       "       [8.000e+00, 1.330e+02, 7.200e+01, 0.000e+00, 0.000e+00, 3.290e+01,\n",
       "        2.700e-01, 3.900e+01],\n",
       "       [5.000e+00, 8.800e+01, 6.600e+01, 2.100e+01, 2.300e+01, 2.440e+01,\n",
       "        3.420e-01, 3.000e+01],\n",
       "       [1.000e+00, 8.900e+01, 6.600e+01, 2.300e+01, 9.400e+01, 2.810e+01,\n",
       "        1.670e-01, 2.100e+01],\n",
       "       [9.000e+00, 1.020e+02, 7.600e+01, 3.700e+01, 0.000e+00, 3.290e+01,\n",
       "        6.650e-01, 4.600e+01],\n",
       "       [1.000e+00, 9.500e+01, 6.600e+01, 1.300e+01, 3.800e+01, 1.960e+01,\n",
       "        3.340e-01, 2.500e+01],\n",
       "       [1.000e+01, 1.150e+02, 0.000e+00, 0.000e+00, 0.000e+00, 3.530e+01,\n",
       "        1.340e-01, 2.900e+01],\n",
       "       [2.000e+00, 8.400e+01, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        3.040e-01, 2.100e+01],\n",
       "       [2.000e+00, 1.100e+02, 7.400e+01, 2.900e+01, 1.250e+02, 3.240e+01,\n",
       "        6.980e-01, 2.700e+01],\n",
       "       [4.000e+00, 1.460e+02, 8.500e+01, 2.700e+01, 1.000e+02, 2.890e+01,\n",
       "        1.890e-01, 2.700e+01],\n",
       "       [6.000e+00, 9.200e+01, 9.200e+01, 0.000e+00, 0.000e+00, 1.990e+01,\n",
       "        1.880e-01, 2.800e+01],\n",
       "       [3.000e+00, 7.800e+01, 5.000e+01, 3.200e+01, 8.800e+01, 3.100e+01,\n",
       "        2.480e-01, 2.600e+01]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array(pima)[:,:-1]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "one_hot_encoder = OneHotEncoder(sparse=False)\n",
    "\n",
    "Y = pima.Outcome\n",
    "Y = one_hot_encoder.fit_transform(np.array(Y).reshape(-1, 1))\n",
    "Y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.20)\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NeuralNetwork(X_train, Y_train, X_val=None, Y_val=None, epochs=10, nodes=[], lr=0.15):\n",
    "    hidden_layers = len(nodes) - 1\n",
    "    weights = InitializeWeights(nodes)\n",
    "\n",
    "    for epoch in range(1, epochs+1):\n",
    "        weights = Train(X_train, Y_train, lr, weights)\n",
    "\n",
    "        if(epoch % 20 == 0):\n",
    "            print(\"Epoch {}\".format(epoch))\n",
    "            print(\"Training Accuracy:{}\".format(Accuracy(X_train, Y_train, weights)))\n",
    "            if X_val.any():\n",
    "                print(\"Validation Accuracy:{}\".format(Accuracy(X_val, Y_val, weights)))\n",
    "            \n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def InitializeWeights(nodes):\n",
    "    layers, weights = len(nodes), []\n",
    "    \n",
    "    for i in range(1, layers):\n",
    "        w = [[np.random.uniform(-1, 1) for k in range(nodes[i-1] + 1)]\n",
    "              for j in range(nodes[i])]\n",
    "        weights.append(np.matrix(w))\n",
    "    \n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ForwardPropagation(x, weights, layers):\n",
    "    activations, layer_input = [x], x\n",
    "    for j in range(layers):\n",
    "        activation = Sigmoid(np.dot(layer_input, weights[j].T))\n",
    "        activations.append(activation)\n",
    "        layer_input = np.append(1, activation) # Augment with bias\n",
    "    \n",
    "    return activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BackPropagation(y, activations, weights, layers):\n",
    "    outputFinal = activations[-1]\n",
    "    error = np.matrix(y - outputFinal)\n",
    "    \n",
    "    for j in range(layers, 0, -1):\n",
    "        currActivation = activations[j]\n",
    "        \n",
    "        if(j > 1):\n",
    "            prevActivation = np.append(1, activations[j-1])\n",
    "        else:\n",
    "            prevActivation = activations[0]\n",
    "        \n",
    "        delta = np.multiply(error, SigmoidDerivative(currActivation))\n",
    "        weights[j-1] += lr * np.multiply(delta.T, prevActivation)\n",
    "\n",
    "        w = np.delete(weights[j-1], [0], axis=1)\n",
    "        error = np.dot(delta, w)\n",
    "    \n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Train(X, Y, lr, weights):\n",
    "    layers = len(weights)\n",
    "    for i in range(len(X)):\n",
    "        x, y = X[i], Y[i]\n",
    "        x = np.matrix(np.append(1, x)) # Augment feature vector\n",
    "        \n",
    "        activations = ForwardPropagation(x, weights, layers)\n",
    "        weights = BackPropagation(y, activations, weights, layers)\n",
    "\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def SigmoidDerivative(x):\n",
    "    return np.multiply(x, 1-x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Predict(item, weights):\n",
    "    layers = len(weights)\n",
    "    item = np.append(1, item)\n",
    "\n",
    "    activations = ForwardPropagation(item, weights, layers)\n",
    "    \n",
    "    outputFinal = activations[-1].A1\n",
    "    index = FindMaxActivation(outputFinal)\n",
    "\n",
    "    y = [0 for i in range(len(outputFinal))]\n",
    "    y[index] = 1\n",
    "    return y\n",
    "\n",
    "\n",
    "def FindMaxActivation(output):\n",
    "    m, index = output[0], 0\n",
    "    for i in range(1, len(output)):\n",
    "        if(output[i] > m):\n",
    "            m, index = output[i], i\n",
    "    \n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Accuracy(X, Y, weights, display=False):\n",
    "    correct = 0\n",
    "\n",
    "    for i in range(len(X)):\n",
    "        x, y = X[i], list(Y[i])\n",
    "        guess = Predict(x, weights)\n",
    "        if display == True:\n",
    "            print(\"\\n\\nInput:\\n\",x,\"\\nPredicted:\\n\",guess,\"\\nActual:\\n\",y)\n",
    "        if(y == guess):\n",
    "            correct += 1\n",
    "        elif display == True:\n",
    "            print(\"mispredicted\")\n",
    "\n",
    "    return correct / len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20\n",
      "Training Accuracy:0.6944444444444444\n",
      "Validation Accuracy:0.5\n",
      "Epoch 40\n",
      "Training Accuracy:0.6388888888888888\n",
      "Validation Accuracy:0.5\n",
      "Epoch 60\n",
      "Training Accuracy:0.6388888888888888\n",
      "Validation Accuracy:0.5\n",
      "Epoch 80\n",
      "Training Accuracy:0.6388888888888888\n",
      "Validation Accuracy:0.5\n",
      "Epoch 100\n",
      "Training Accuracy:0.6388888888888888\n",
      "Validation Accuracy:0.5\n",
      "Epoch 120\n",
      "Training Accuracy:0.6388888888888888\n",
      "Validation Accuracy:0.5\n",
      "Final weights:\n",
      " [matrix([[ 0.80727185,  0.72212309, -0.89553903,  0.07957729,  0.33676418,\n",
      "          1.22699133, -0.25394636,  0.00805894,  0.4489616 ],\n",
      "        [-0.44838602, -0.72553872,  0.73713709,  0.95037424, -0.90440351,\n",
      "          2.04926507, -0.0505871 , -0.70365126,  0.70075909],\n",
      "        [-0.58507007,  0.66275995, -0.19553254, -0.77008572, -0.90157562,\n",
      "          0.0399853 ,  0.07214572,  0.67606312, -0.10328383],\n",
      "        [-0.71643619, -0.64933216,  0.25856123, -0.4142929 ,  0.98403902,\n",
      "          0.31896141,  0.38947501,  0.63211577,  0.76514096],\n",
      "        [-0.25309492,  0.55255194, -0.44747897, -0.61843957,  0.80462849,\n",
      "         -0.31919962,  0.01109573, -0.50757039,  0.24850415],\n",
      "        [ 0.21005498, -0.07902232,  0.99912713, -0.43940918, -0.55644526,\n",
      "          0.56586082,  0.28685403,  0.28479954, -0.26666233]]), matrix([[ 0.91328677, -0.24908219, -0.70005926,  0.59325932,  0.76828394,\n",
      "          0.5274213 ,  0.43112367],\n",
      "        [ 1.24958557, -0.97392743, -0.50037879,  0.40612746,  0.63397445,\n",
      "          0.5170544 , -0.85511788],\n",
      "        [ 1.02590255,  0.70076739,  0.38985524, -0.48186844, -0.2731575 ,\n",
      "         -0.30099507, -0.54537281],\n",
      "        [ 0.42581094,  0.5226352 , -0.4353518 , -0.23369584, -0.16076544,\n",
      "          0.58449975,  0.77719278],\n",
      "        [ 0.09292066,  1.1539252 ,  1.41787055,  0.49401102, -1.27902591,\n",
      "          0.62866379,  0.55897385],\n",
      "        [ 0.66345255,  1.09691963,  0.00851432,  0.2594119 ,  0.83080108,\n",
      "          0.91534771, -0.44437086],\n",
      "        [-0.62434652, -0.85310864,  0.86888991,  0.81320143, -0.49171313,\n",
      "          0.6990369 , -0.40842318],\n",
      "        [ 1.37276353, -1.12790354, -0.30632962,  0.42574898,  1.09491206,\n",
      "         -0.13717273, -0.82988151],\n",
      "        [-0.30943292,  0.47955085,  0.6960016 , -0.57185972, -0.87930148,\n",
      "          0.76592667,  0.20826556],\n",
      "        [-0.42346011,  0.52688136,  0.19504879, -0.22510697,  0.92837975,\n",
      "         -0.47916997,  0.06085841],\n",
      "        [ 0.59213228,  0.13493948, -1.01186619,  0.06247522, -0.06295619,\n",
      "         -0.63885162, -0.54755989],\n",
      "        [ 0.69641909,  1.0113238 , -0.43547754, -0.60471641,  0.88279284,\n",
      "         -0.13793229, -0.20464776]]), matrix([[-0.46793578,  1.06709621,  0.9219703 ,  0.4427257 , -0.31676971,\n",
      "         -0.73518658, -0.63385272,  0.40377998,  1.04859694,  0.08635989,\n",
      "         -0.47763632,  0.6103287 ,  0.19178186],\n",
      "        [-0.58781997,  0.16658822, -0.63263468,  0.60310061,  0.13738751,\n",
      "          1.15389634, -0.35928275, -0.66604622, -1.07881517,  0.84319927,\n",
      "         -0.74109889, -0.5877544 ,  0.21589139]])]\n"
     ]
    }
   ],
   "source": [
    "f = len(X[0])\n",
    "o = len(Y[0])\n",
    "\n",
    "layers = [f, 6, 12, o]\n",
    "lr, epochs = 0.15, 120\n",
    "\n",
    "weights = NeuralNetwork(X_train, Y_train, X_val, Y_val, epochs=epochs, nodes=layers, lr=lr);\n",
    "print(\"Final weights:\\n\",weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Input:\n",
      " [  5.    137.    108.      0.      0.     48.8     0.227  37.   ] \n",
      "Predicted:\n",
      " [1, 0] \n",
      "Actual:\n",
      " [0.0, 1.0]\n",
      "mispredicted\n",
      "\n",
      "\n",
      "Input:\n",
      " [  9.    171.    110.     24.    240.     45.4     0.721  54.   ] \n",
      "Predicted:\n",
      " [1, 0] \n",
      "Actual:\n",
      " [0.0, 1.0]\n",
      "mispredicted\n",
      "\n",
      "\n",
      "Input:\n",
      " [  1.    103.     30.     38.     83.     43.3     0.183  33.   ] \n",
      "Predicted:\n",
      " [1, 0] \n",
      "Actual:\n",
      " [1.0, 0.0]\n",
      "\n",
      "\n",
      "Input:\n",
      " [ 6.    93.    50.    30.    64.    28.7    0.356 23.   ] \n",
      "Predicted:\n",
      " [1, 0] \n",
      "Actual:\n",
      " [1.0, 0.0]\n",
      "\n",
      "\n",
      "Input:\n",
      " [ 3.    88.    58.    11.    54.    24.8    0.267 22.   ] \n",
      "Predicted:\n",
      " [1, 0] \n",
      "Actual:\n",
      " [1.0, 0.0]\n",
      "\n",
      "\n",
      "Input:\n",
      " [  8.    125.     96.      0.      0.      0.      0.232  54.   ] \n",
      "Predicted:\n",
      " [1, 0] \n",
      "Actual:\n",
      " [0.0, 1.0]\n",
      "mispredicted\n",
      "\n",
      "\n",
      "Input:\n",
      " [  5.    116.     74.      0.      0.     25.6     0.201  30.   ] \n",
      "Predicted:\n",
      " [1, 0] \n",
      "Actual:\n",
      " [1.0, 0.0]\n",
      "\n",
      "\n",
      "Input:\n",
      " [  4.    110.     92.      0.      0.     37.6     0.191  30.   ] \n",
      "Predicted:\n",
      " [1, 0] \n",
      "Actual:\n",
      " [1.0, 0.0]\n",
      "\n",
      "\n",
      "Input:\n",
      " [  1.    103.     80.     11.     82.     19.4     0.491  22.   ] \n",
      "Predicted:\n",
      " [1, 0] \n",
      "Actual:\n",
      " [1.0, 0.0]\n",
      "\n",
      "\n",
      "Input:\n",
      " [4.00e+00 1.29e+02 8.60e+01 2.00e+01 2.70e+02 3.51e+01 2.31e-01 2.30e+01] \n",
      "Predicted:\n",
      " [1, 0] \n",
      "Actual:\n",
      " [1.0, 0.0]\n",
      "\n",
      "\n",
      "Input:\n",
      " [  2.    112.     66.     22.      0.     25.      0.307  24.   ] \n",
      "Predicted:\n",
      " [1, 0] \n",
      "Actual:\n",
      " [1.0, 0.0]\n",
      "\n",
      "\n",
      "Input:\n",
      " [  0.    105.     64.     41.    142.     41.5     0.173  22.   ] \n",
      "Predicted:\n",
      " [1, 0] \n",
      "Actual:\n",
      " [1.0, 0.0]\n",
      "\n",
      "\n",
      "Input:\n",
      " [  1.     97.     66.     15.    140.     23.2     0.487  22.   ] \n",
      "Predicted:\n",
      " [1, 0] \n",
      "Actual:\n",
      " [1.0, 0.0]\n",
      "\n",
      "\n",
      "Input:\n",
      " [  3.    126.     88.     41.    235.     39.3     0.704  27.   ] \n",
      "Predicted:\n",
      " [1, 0] \n",
      "Actual:\n",
      " [1.0, 0.0]\n",
      "\n",
      "\n",
      "Input:\n",
      " [  0.    146.     82.      0.      0.     40.5     1.781  44.   ] \n",
      "Predicted:\n",
      " [1, 0] \n",
      "Actual:\n",
      " [1.0, 0.0]\n",
      "\n",
      "\n",
      "Input:\n",
      " [  0.    109.     88.     30.      0.     32.5     0.855  38.   ] \n",
      "Predicted:\n",
      " [1, 0] \n",
      "Actual:\n",
      " [0.0, 1.0]\n",
      "mispredicted\n",
      "\n",
      "\n",
      "Input:\n",
      " [  7.    100.      0.      0.      0.     30.      0.484  32.   ] \n",
      "Predicted:\n",
      " [1, 0] \n",
      "Actual:\n",
      " [0.0, 1.0]\n",
      "mispredicted\n",
      "\n",
      "\n",
      "Input:\n",
      " [ 15.    136.     70.     32.    110.     37.1     0.153  43.   ] \n",
      "Predicted:\n",
      " [1, 0] \n",
      "Actual:\n",
      " [0.0, 1.0]\n",
      "mispredicted\n",
      "\n",
      "\n",
      "Input:\n",
      " [  5.    109.     75.     26.      0.     36.      0.546  60.   ] \n",
      "Predicted:\n",
      " [1, 0] \n",
      "Actual:\n",
      " [1.0, 0.0]\n",
      "\n",
      "\n",
      "Input:\n",
      " [  8.   133.    72.     0.     0.    32.9    0.27  39.  ] \n",
      "Predicted:\n",
      " [1, 0] \n",
      "Actual:\n",
      " [0.0, 1.0]\n",
      "mispredicted\n",
      "Testing Accuracy: 0.65\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing Accuracy: {}\".format(Accuracy(X_test, Y_test, weights, display = True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score: -0.538462\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      1.00      0.79        13\n",
      "           1       0.00      0.00      0.00         7\n",
      "\n",
      "   micro avg       0.65      0.65      0.65        20\n",
      "   macro avg       0.33      0.50      0.39        20\n",
      "weighted avg       0.42      0.65      0.51        20\n",
      " samples avg       0.65      0.65      0.65        20\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "\n",
      "[[13  0]\n",
      " [ 7  0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "Y_result = []\n",
    "Converted = []\n",
    "Actual = []\n",
    "Prediction = []\n",
    "for x in X_test:\n",
    "    guess = Predict(x,weights)\n",
    "    Y_result.append(guess)\n",
    "    for i in range(len(guess)):\n",
    "        if guess[i] ==1:\n",
    "            Converted.append(i)\n",
    "for i in range(len(Y_test)):\n",
    "    for j in range(len(Y_test[0])):\n",
    "        if Y_test[i][j] ==1:\n",
    "            Actual.append(j)\n",
    "            \n",
    "print(\"R2 Score: %f\" % r2_score(Y_test,Y_result))\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(classification_report(Y_test,Y_result))\n",
    "print(\"\\nConfusion Matrix:\\n\")\n",
    "print(confusion_matrix(Actual, Converted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEKCAYAAAAMzhLIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAsBElEQVR4nO3deXhUhdnG4d/Lvod9J+w7QYQA7oorrojYarWutWirtf3aKiguVFFxaatWLcXd1morAURRsVQRq6KAQjb2sIV9XxJCtvf7YwZNaQhjyGQmM899XbmSyZyZeXIg8+ScM/Mec3dERESOpFqkA4iISHRTUYiISJlUFCIiUiYVhYiIlElFISIiZVJRiIhImcJWFGb2kpltNbP0I1xvZva0ma00s1QzGxiuLCIiUn7h3KJ4BRhexvXnA92DH6OBP4cxi4iIlFPYisLd5wI7y1hkBPCaB8wDGptZm3DlERGR8qkRwcduB6wvcTk7+L1Nhy9oZqMJbHVQv379Qb169aqUgCIiVVmxO6u355CbX0Thnq0U5e6x8txPJIuitMClzhNx98nAZIDk5GRfsGBBOHOJiFR5n67Yxl1T00jYdYCm1Yzsl24v97ymSBZFNtChxOX2wMYIZRERiQl7cguYMDOTtxZm06VFfd665USqmTH0T7vL/fwayaKYAdxmZm8CQ4E97v4/u51ERCQ0H6Rv5t6309mZk8/Pz+jK7Wd1p07N6gAU7d+xubz3G7aiMLM3gDOA5maWDdwP1ARw90nAe8AFwEogF7ghXFlERGLZ1n15jJ+RwXtpm+nTphEvXz+Yfu0SKuz+w1YU7v6jo1zvwK3henwRkVjn7qR8vYEH383kQEERd5zXk9GndaFm9Yp9QWskdz2JiEg5Ze/K5e5p6cxdvo1BHZvw6Kj+dGvZICyPpaIQEalCioudv85by6MfLAXgd5f05ZoTOlKtWrle+RoSFYWISBWxatt+xkxJZcHaXZzWowUPj+xH+yb1wv64KgoRkShXUFTM5LlZPPXvFdStWZ0nfnAcowa2wyx8WxElqShERKJY+oY9jElJJWPjXi5Ias34S/rSsmGdSs2gohARiUJ5BUU8/e8V/GVuFk3q1WLSjwcyvF9kxuGpKEREosz8NTsZMyWVrO05/GBQe+65sA8J9WpGLI+KQkQkSuw/WMhjHyzltS/W0r5JXV67cQin9WgR6VgqChGRaPDJ8m3cPTWNjXsOcP1JnbjjvJ7Urx0dT9HRkUJEJE7tzs3ngXczmfr1Brq2qM+UW05kUMemkY71X1QUIiIR8l7aJu57O53duQXcNqwbt53Z7dshftFERSEiUsm27s3j3rfTmZWxhX7tGvHqjUPo27bihvhVNBWFiEglcXfeWpjNhHczySssZszwXvz01M7UqOAhfhVNRSEiUgnW78zlrqlp/GfldoZ0asrEUUl0aRGeIX4VTUUhIhJGRcXOa1+s4bEPllHN4MFL+3H1kMSwDvGraCoKEZEwWbl1H3dOSeXrdbs5o2cLHhqZRLvGdSMd63tTUYiIVLCComL+8skqnv73SurVrs4frziOSwdU3hC/iqaiEBGpQGnZe7hjymKWbt7Hhf3b8LtL+tK8Qe1IxzomKgoRkQqQV1DEH2cv5/m5WTRvUJu/XDOI8/q2jnSsCqGiEBE5Rl9m7WDs1DRWb8/hysEduOuC3iTUjdwQv4qmohARKad9eQU8+sFS/jZvHR2a1uX1m4ZycrfmkY5V4VQUIiLl8PHSrYyblsamvXn85JTO/ObcHtSrFZtPqbH5U4mIhMnOnHwefDeTad9soHvLBqT87CQGJjaJdKywUlGIiITA3Xk3dRPjZ2Sw50ABt5/VnVuHdaV2jegb4lfRVBQiIkexZW8e46alM3vJFvq3T+BvNw2ld5tGkY5VaVQUIiJH4O78Y/56HnpvCfmFxYy7oDc3nNwp6of4VTQVhYhIKdbtyGXs1FQ+X7WDoZ2b8uio/nRqXj/SsSJCRSEiUkJRsfPyZ6t54sNl1KhWjYdHJnHl4A5VaohfRVNRiIgELd8SGOK3aP1uzuzVkodG9qNNQtUb4lfRVBQiEvfyC4v585xVPPPxChrWqclTVw7gkuPaVtkhfhVNRSEicW3x+t3cOSWVZVv2MWJAW+67qA/NqvgQv4qmohCRuHQgv4g//GsZL/5nNS0b1uGFa5M5u0+rSMeKSioKEYk7X6zawdipqazdkctVQxMZe34vGtWJnSF+FU1FISJxY29eAY+8t5Q3vlpHx2b1+PtPh3JS19gb4lfRVBQiEhdmZ27hnunpbN2Xx+jTuvB/Z/egbq3YH79REcJaFGY2HHgKqA684O4TD7s+AfgbkBjM8oS7vxzOTCISX3bsP8jv3slkxuKN9GzVkEnXDGJAh8aRjlWlhK0ozKw68CxwDpANzDezGe6eWWKxW4FMd7/YzFoAy8zsdXfPD1cuEYkP7s6MxRsZPyOD/QcL+b+ze/CzM7pSq0Z8jd+oCOHcohgCrHT3LAAzexMYAZQsCgcaWuDFyg2AnUBhGDOJSBzYtOcA90xL599LtzKgQ2Meu7w/PVo1jHSsKiucRdEOWF/icjYw9LBlngFmABuBhsAV7l58+B2Z2WhgNEBiYmJYwopI1Vdc7Lwxfx2PvLeUwuJi7rmwNzec3JnqcTx+oyKEsyhK+5fxwy6fBywCzgS6Av8ys0/dfe9/3ch9MjAZIDk5+fD7EBFhzfYcxk5NZV7WTk7q2oyJl/UnsVm9SMeKCeEsimygQ4nL7QlsOZR0AzDR3R1YaWargV7AV2HMJSIxpLComJc+W83vP1xOrerVmHhZElcM7qDxGxUonEUxH+huZp2BDcCVwFWHLbMOOAv41MxaAT2BrDBmEpEYsmTTXsakpJKavYeze7diwqX9aJ1QJ9KxYk7YisLdC83sNmAWgZfHvuTuGWZ2S/D6ScCDwCtmlkZgV9UYd98erkwiEhsOFhbx7MereO7jlSTUrckzVx3PhUlttBURJmF9H4W7vwe8d9j3JpX4eiNwbjgziEhs+XrdLsZMSWXF1v2MPL4d913Uhyb1a0U6VkzTO7NFpErIzS/k9x8u56XPVtO6UR1evn4ww3q1jHSsuKCiEJGo99nK7Yydmsr6nQf48QmJjBnei4Ya4ldpVBQiErX2HCjgkfeW8Ob89XRuXp9/jD6BoV2aRTpW3FFRiEhU+jBjM/dMT2f7/oPcfHpgiF+dmhriFwkqChGJKtv2HWT8OxnMTN1Er9YNeeG6ZPq3bxzpWHFNRSEiUcHdmb5oA797J5Pcg0X89twe3Hx6V2pW1xC/SFNRiEjEbdh9gHHT0pizbBsDEwND/Lq11BC/aKGiEJGIKS52Xv9qHRPfW0Kxw/0X9+HaEztpiF+UUVGISERkbdvP2JQ0vlqzk1O6NeeRy5Lo0FRD/KKRikJEKlVhUTHPf7qaP85eTp0a1Xjs8v78YFB7jd+IYioKEak0mRv3cmfKYtI37OW8vq14cEQ/WjbSEL9op6IQkbDLKyjimY9WMumTVTSuV4s/Xz2Q85PaRDqWhEhFISJhtXDtTu6cksqqbTmMGtieey/qTeN6GuJXlagoRCQscg4W8visZbz6xRraJtTl1RuHcHqPFpGOJeWgohCRCjd3+TbumprGht0HuO7EjtwxvBcNauvppqrSv5yIVJg9uQU8ODOTKQuz6dKiPm/dciKDOzWNdCw5RiEXhZnVd/eccIYRkarrg/RN3Pt2Bjtz8vn5GV25/azuGuIXI45aFGZ2EvAC0ABINLPjgJvd/efhDici0W/rvjzufzuD99M306dNI16+fjD92iVEOpZUoFC2KP4InAfMAHD3xWZ2WlhTiUjUc3dSvt7Ag+9mcqCgiDvO68no07poiF8MCmnXk7uvP+xdk0XhiSMiVUH2rlzunpbO3OXbSO7YhImj+tOtZYNIx5IwCaUo1gd3P7mZ1QJuB5aEN5aIRKPiYuev89by6AdLAfjdJX255oSOVNMQv5gWSlHcAjwFtAOygQ8BHZ8QiTMrt+5nbEoqC9bu4rQeLXh4ZD/aN9EQv3gQSlH0dPerS37DzE4GPgtPJBGJJgVFxUyem8VTs1dQt1Z1fv+D47hsYDsN8YsjoRTFn4CBIXxPRGJM+oY93DkllcxNe7kgqTW/u6QfLRrWjnQsqWRHLAozOxE4CWhhZr8ucVUjQC+OFolheQVFPPXvFUyem0XT+rWY9OOBDO+nIX7xqqwtiloE3jtRAyh5TsK9wOXhDCUikTN/zU7GTEkla3sOPxjUnnsu7ENCvZqRjiURdMSicPdPgE/M7BV3X1uJmUQkAvYfLOSxD5by2hdrad+kLn/9yRBO7a4hfhLaMYpcM3sc6At8e4YRdz8zbKlEpFLNWbaVcdPS2bjnADec3InfntuT+hriJ0Gh/E94HfgHcBGBl8peB2wLZygRqRy7cvJ5cGYmU7/eQLeWDZhyy0kM6tgk0rEkyoRSFM3c/UUz+2WJ3VGfhDuYiISPu/N++mbuezud3bkF/OLMbtx2Zjdq19DrVOR/hVIUBcHPm8zsQmAj0D58kUQknLbuzePet9OZlbGFpHYJvHbjUPq0bRTpWBLFQimKCWaWAPyGwPsnGgG/CmcoEal47s5bC7KZMDOTg4XFjD2/Fzed0pkaGuInR3HUonD3d4Nf7gGGwbfvzBaRKmL9zlzumprGf1ZuZ0inpkwclUSXFhriJ6Ep6w131YEfEpjx9IG7p5vZRcDdQF3g+MqJKCLlVVTsvPr5Gh6ftYzq1YwHL+3H1UMSNcRPvpeytiheBDoAXwFPm9la4ERgrLtPD+XOzWw4gYGC1YEX3H1iKcucATwJ1AS2u/vpoccXkSNZsWUfY1JS+Xrdbs7o2YKHRybRtnHdSMeSKqisokgG+rt7sZnVAbYD3dx9cyh3HNwieRY4h8DU2flmNsPdM0ss0xh4Dhju7uvMrGU5fw4RCSooKmbSnFX86aOV1K9dnSevGMCIAW01xE/KrayiyHf3YgB3zzOz5aGWRNAQYKW7ZwGY2ZvACCCzxDJXAVPdfV3wcbZ+r/Qi8l/Ssvdwx5TFLN28j4v6t2H8JX1p3kBD/OTYlFUUvcwsNfi1AV2Dlw1wd+9/lPtuB6wvcTkbGHrYMj2AmmY2h8A8qafc/bXD78jMRgOjARITE4/ysCLxJ6+giD/OXs7zc7No3qA2k68ZxLl9W0c6lsSIsoqi9zHed2nbuV7K4w8CziJwgPwLM5vn7sv/60buk4HJAMnJyYffh0hcm5e1g7EpqazZkcuVgztw1wW9SairIX5SccoaCnisgwCzCRwMP6Q9gTfrHb7MdnfPAXLMbC5wHLAcESnTvrwCJr6/lNe/XEdi03q8ftNQTu7WPNKxJAaFc+rXfKC7mXUGNgBXEjgmUdLbwDNmVoPAWPOhwB/DmEkkJny8dCt3T0tjy948bjqlM78+twf1ammIn4RH2P5nuXuhmd0GzCLw8tiX3D3DzG4JXj/J3ZeY2QdAKlBM4CW06eHKJFLV7czJ54F3Mpi+aCPdWzbguZ+dxPGJGuIn4WXuR9/lb2Z1gUR3Xxb+SGVLTk72BQsWRDqGSKVyd95N3cT4GRnsOVDArcO68fNhXTXET0JmZgvdPbk8tz3qFoWZXQw8QWDXUGczGwA84O6XlOcBReT72bwnj3umpzN7yRb6t0/g9Z8OpVdrDfGTyhPKrqfxBN4TMQfA3ReZWafwRRIRCGxFvDl/PQ/PXEJ+UTHjLujNDSd30hA/qXShFEWhu+/RuzpFKs/aHTmMTUnji6wdnNClKRMv60+n5vUjHUviVChFkW5mVwHVzaw7cDvweXhjicSnomLn5c9W88SHy6hZrRoPj0ziysEdNMRPIiqUovgFMA44CPydwKuYJoQzlEg8WrZ5H3empLJ4/W7O6tWSCSP70SZBQ/wk8kIpip7uPo5AWYhIBcsvLOa5OSt59uOVNKxTk6euHMAlx2mIn0SPUIriD2bWBngLeNPdM8KcSSRuLFq/mzFTUlm2ZR8jBrTlvov60ExD/CTKhHKGu2Fm1prASYwmm1kj4B/urt1PIuV0IL+IP/xrGS/+ZzUtG9bhxeuSOat3q0jHEilVSO/MDo4Xf9rMPgbuBO5DxylEyuXzVdsZm5LGup25XDU0kbHn96JRHQ3xk+gVyhvuegNXAJcDO4A3gd+EOZdIzNmbV8Aj7y3lja/W0bFZPd746Qmc2LVZpGOJHFUoWxQvA28A57r74dNfRSQEszO3MG56Gtv2HWT0aV34v7N7ULeWxm9I1RDKMYoTKiOISCzasf8gv3snkxmLN9KrdUMmX5PMcR0aRzqWyPdyxKIws3+6+w/NLI3/PuFQqGe4E4lb7s6MxRsZPyOD/QcL+b+ze/CzM7pSq4bGb0jVU9YWxS+Dny+qjCAisWLj7gPcMz2dj5ZuZUCHxjx2eX96tGoY6Vgi5VbWGe42Bb/8ubuPKXmdmT0KjPnfW4nEr+Ji543563jkvaUUFTv3XtSH60/qRHWN35AqLpSD2efwv6VwfinfE4lbq7fnMDYllS9X7+Tkbs14ZGR/EpvVi3QskQpR1jGKnwE/B7qYWWqJqxoCn4U7mEhVUFhUzEufreb3Hy6nVo1qPDoqiR8md9D4DYkpZW1R/B14H3gEGFvi+/vcfWdYU4lUAUs27WVMSiqp2Xs4p08rJlzaj1aN6kQ6lkiFK6so3N3XmNmth19hZk1VFhKvDhYW8exHK3luzioS6tbkmauO58KkNtqKkJh1tC2Ki4CFBF4eW/K3wIEuYcwlEpW+XreLMVNSWbF1P5cd3457L+pDk/q1Ih1LJKzKetXTRcHPnSsvjkh0ys0v5IlZy3n589W0aVSHl28YzLCeLSMdS6RShDLr6WRgkbvnmNmPgYHAk+6+LuzpRKLAZyu3M3ZqKut3HuCaEzpy5/CeNNQQP4kjobw89s/AcWZ2HIHJsS8CfwVOD2cwkUjbc6CAh2cu4R8L1tO5eX3+MfoEhnbRED+JP6EURaG7u5mNAJ5y9xfN7LpwBxOJpFkZm7l3ejo7cvK55fSu/Ors7tSpqSF+Ep9CKYp9ZnYXcA1wqplVB7TdLTFp276DjJ+Rwcy0TfRu04gXrxtMUvuESMcSiahQiuIK4CrgRnffbGaJwOPhjSVSudydad9s4IF3M8k9WMRvz+3Bzad3pWZ1DfETCWXM+GYzex0YbGYXAV+5+2vhjyZSOTbsPsC4aWnMWbaNgYmBIX7dWmqIn8ghobzq6YcEtiDmEHgvxZ/M7A53nxLmbCJhVVzsvP7lWia+vxQHxl/ch2tO1BA/kcOFsutpHDDY3bcCmFkLYDagopAqK2vbfsampPHVmp2c2r05D49MokNTDfETKU0oRVHtUEkE7QC041aqpMKiYp7/dDV/nL2cOjWq8fjl/bl8UHuN3xApQyhF8YGZzSJw3mwIHNx+L3yRRMIjY+MexqSkkr5hL+f1bcWDI/rRUkP8RI4qlIPZd5jZZcApBI5RTHb3aWFPJlJB8gqK+NNHK5j0SRZN6tXiz1cP5PykNpGOJVJllHU+iu7AE0BXIA34rbtvqKxgIhVh4dqd3DkllVXbchg1sD33XtSbxvU0xE/k+yhri+Il4DVgLnAx8CfgssoIJXKscg4W8visZbz6xRraJtTl1RuHcHqPFpGOJVIllVUUDd39+eDXy8zs68oIJHKs5i7fxl1T09i45wDXntCRO4b3okHtUA7HiUhpyvrtqWNmx/PdeSjqlrzs7kctDjMbDjwFVAdecPeJR1huMDAPuELvz5Dy2p2bz4SZS5iyMJsuLerzz5tPZHCnppGOJVLllVUUm4A/lLi8ucRlB84s646DM6GeBc4BsoH5ZjbD3TNLWe5RYNb3iy7ynffTNnHv2xnsys3n52d05fazNMRPpKKUdeKiYcd430OAle6eBWBmbwIjgMzDlvsFkAIMPsbHkzi0dV8e97+dwfvpm+nbthGv3DCYfu00xE+kIoVzx207YH2Jy9nA0JILmFk7YCSBrZMjFoWZjQZGAyQmJlZ4UKl63J0pC7OZMHMJBwqKuHN4T356ahcN8RMJg3AWRWlvdfXDLj8JjHH3orLeGevuk4HJAMnJyYffh8SZ9TtzuXtaGp+u2M7gTk2YOKo/XVs0iHQskZgVzqLIBjqUuNwe2HjYMsnAm8GSaA5cYGaF7j49jLmkiioudl77Yg2PzVqGAQ+M6MuPh3akmob4iYRVKNNjDbga6OLuDwTPR9Ha3b86yk3nA93NrDOwAbiSwHktvuXunUs8zivAuyoJKc3KrfsZm5LKgrW7OK1HCx4e2Y/2TTTET6QyhLJF8RxQTOA4wgPAPkI4+OzuhWZ2G4FXM1UHXnL3DDO7JXj9pGMJLvGhoKiYyXOzeGr2CurWqs7vf3Aclw1spyF+IpUolKIY6u4DzewbAHffZWYhzUBw9/c4bIDgkQrC3a8P5T4lfqRv2MOdU1LJ3LSXC5PaMP6SvrRoWDvSsUTiTihFURB8r4PDt+ejKA5rKolreQVFPPXvFUyem0XT+rWY9ONBDO/XOtKxROJWKEXxNDANaGlmDwGXA/eENZXErflrdjJmSipZ23P4YXJ7xl3Qh4R6NSMdSySuhTJm/HUzWwicReAlr5e6+5KwJ5O4sv9gIY99sJTXvlhL+yZ1+dtPhnJK9+aRjiUihPaqp0QgF3in5PfcfV04g0n8+HjZVsZNTWPT3jxuOLkTvz23J/U1xE8kaoTy2ziTwPEJA+oAnYFlQN8w5pI4sCsnnwffzWTqNxvo1rIBU245iUEdm0Q6logcJpRdT0klL5vZQODmsCWSmOfuvJe2mftnpLM7t4Dbz+zGrWd2o3YNDfETiUbfe/ve3b8OjgUX+d627s3jnunpfJi5haR2Cbx241D6tG0U6VgiUoZQjlH8usTFasBAYFvYEklMcnfeWpDNgzMzyS8s5q7ze/GTUzpTQ0P8RKJeKFsUDUt8XUjgmEVKeOJILFq/M5e7pqbxn5XbGdK5KRMvS6KLhviJVBllFkXwjXYN3P2OSsojMaSo2Hn18zU8PmsZ1asZEy7tx1VDEjXET6SKOWJRmFmN4LymgZUZSGLDii37uDMllW/W7WZYzxY8NDKJto3rRjqWiJRDWVsUXxE4HrHIzGYAbwE5h65096lhziZVUH5hMZM+WcUzH62kfu3qPHnFAEYMaKshfiJVWCjHKJoCOwhMjz30fgoHVBTyX1Kzd3PnlFSWbt7Hxce15f6L+9C8gYb4iVR1ZRVFy+ArntL5riAO0Vnm5Ft5BUX88V/Lef7TLFo0rM3z1yZzTp9WkY4lIhWkrKKoDjQgtFOaSpyal7WDsSmprNmRy4+GdGDs+b1JqKshfiKxpKyi2OTuD1RaEqlS9uUVMPH9pbz+5ToSm9bj7zcN5aRuGuInEovKKgodfZRSfbR0C+OmpbNlbx43ndKZX5/bg3q1NMRPJFaV9dt9VqWlkCphZ04+D7yTwfRFG+nRqgHPXX0SxydqiJ9IrDtiUbj7zsoMItHL3XkndRPjZ2SwL6+AX57VnVuHdaNWDY3fEIkH2l8gZdq8JzDEb/aSLRzXPoFHLx9Kr9Ya4icST1QUUip3583563l45hIKiosZd0FvbjylM9U1fkMk7qgo5H+s3ZHD2JQ0vsjawQldmjLxsv50al4/0rFEJEJUFPKtomLn5c9W88SHy6hZrRqPXJbEFckdNMRPJM6pKASAZZsDQ/wWr9/N2b1bMuHSJFon1Il0LBGJAiqKOJdfWMxzc1by7McraVinJk//6Hgu7t9GQ/xE5Fsqiji2aP1uxkxJZdmWfYwY0Jb7L+5L0/q1Ih1LRKKMiiIOHcgv4vcfLuOlz1bTsmEdXrwumbN6a4ifiJRORRFnPl+1nbEpaazbmctVQxMZe34vGtXRED8ROTIVRZzYm1fAI+8t4Y2v1tOpWT3e+OkJnNi1WaRjiUgVoKKIA7MztzBuehrb9h3k5tO68Kuze1C3VvVIxxKRKkJFEcN27D/I+HcyeWfxRnq1bsjz1ybTv33jSMcSkSpGRRGD3J0ZizcyfkYG+w8W8utzenDL6V01xE9EykVFEWM27j7APdPT+WjpVgZ0aMxjl/enR6uGkY4lIlWYiiJGFBc7f/9qHRPfX0pRsXPvRX24/qROGuInIscsrEVhZsOBpwicf/sFd5942PVXA2OCF/cDP3P3xeHMFItWb89hbEoqX67eycndmvHIyP4kNqsX6VgiEiPCVhRmVh14FjgHyAbmm9kMd88ssdhq4HR332Vm5wOTgaHhyhRrCouKefE/q/nDv5ZTq0Y1HhvVnx8kt9f4DRGpUOHcohgCrHT3LAAzexMYAXxbFO7+eYnl5wHtw5gnpizZtJcxKamkZu/hnD6tmHBpP1o10hA/Eal44SyKdsD6EpezKXtr4SfA+6VdYWajgdEAiYmJFZWvSjpYWMSzH63kuTmraFyvJs9eNZALklprK0JEwiacRVHaM5eXuqDZMAJFcUpp17v7ZAK7pUhOTi71PuLBwrW7GJOSysqt+7ns+Hbce1EfmmiIn4iEWTiLIhvoUOJye2Dj4QuZWX/gBeB8d98RxjxVVm5+IY/PWsYrn6+hTaM6vHzDYIb1bBnpWCISJ8JZFPOB7mbWGdgAXAlcVXIBM0sEpgLXuPvyMGapsv6zYjtjp6aSvesA15zQkTuH96ShhviJSCUKW1G4e6GZ3QbMIvDy2JfcPcPMbglePwm4D2gGPBfcx17o7snhylSV7DlQwEMzM/nngmw6N6/PP28+kSGdm0Y6lojEIXOvWrv8k5OTfcGCBZGOEVazMjZz7/R0duTkM/q0LvzyrO7UqakhfiJSfma2sLx/iOud2VFk276DjJ+Rwcy0TfRu04gXrxtMUvuESMcSkTinoogC7s60bzbwwLuZ5B4s4o7zejL6tC7UrK4hfiISeSqKCNuw+wB3T03jk+XbGNSxCY+OSqJbSw3xE5HooaKIkOJi529fruXR95fiwPiL+3DtiZ2opiF+IhJlVBQRsGrbfsampDJ/zS5O7d6ch0cm0aGphviJSHRSUVSiwqJiJn+axZOzV1CnRjUev7w/lw/SED8RiW4qikqSsXEPY1JSSd+wl+F9W/PApX1p2VBD/EQk+qkowiyvoIg/fbSCSZ9k0aReLf589UDOT2oT6VgiIiFTUYTRgjU7uTMllaxtOVw+qD33XNibxvU0xE9EqhYVRRjkHAwM8Xv1izW0TajLazcO4bQeLSIdS0SkXFQUFWzu8m3cNTWNjXsOcN2JnbjjvJ7Ur63VLCJVl57BKsju3HwmzFzClIXZdGlRn7duPpHkThriJyJVn4qiAryftol7385gV24+tw7ryi/O1BA/EYkdKopjsHVvHve9ncEHGZvp27YRr944mL5tNcRPRGKLiqIc3J0pC7N58N1M8gqLGTO8Fzed2llD/EQkJqkovqf1O3O5e1oan67YzuBOTZg4qj9dWzSIdCwRkbBRUYSouNh57Ys1PDZrGQY8OKIvVw/tqCF+IhLzVBQhWLl1H2NS0li4dhen92jBQyP70b6JhviJSHxQUZShoKiYyXOzeGr2CurVrs4ffngcI49vpyF+IhJXVBRHkL5hD3dMSWXJpr1cmNSG8Zf0pUXD2pGOJSJS6VQUh8krKOLJ2St4/tMsmtavxaQfD2J4v9aRjiUiEjEqihK+Wr2TsSmpZG3P4YrkDtx9QW8S6tWMdCwRkYhSUQD7Dxby6PtL+eu8tbRvUpe//WQop3RvHulYIiJRIe6L4uNlWxk3NY1Ne/O48eTO/Pa8HtSrFferRUTkW3H7jLgrJ58H381k6jcb6NayAVNuOYlBHZtEOpaISNSJu6Jwd2ambeL+tzPYc6CA28/sxq1ndqN2DQ3xExEpTVwVxZa9edw7PZ0PM7eQ1C6Bv900lN5tGkU6lohIVIuLonB3/rlgPRNmLiG/sJi7zu/FT07pTA0N8RMROaqYL4p1O3K5a1oqn63cwZDOTXl0VH86N68f6VgiIlVGzBZFUbHzyudreGLWMqpXMyZc2o+rhiRqiJ+IyPcUk0WxYss+7kxJ5Zt1uxnWswUPjUyibeO6kY4lIlIlxVRR5BcWM+mTVfzpoxU0qF2DJ68YwIgBbTXET0TkGMRMUSxev5sxKaks3byPi49ry/0X96F5Aw3xExE5VlW+KA7kF/Hk7OU8/2kWLRrW5vlrkzmnT6tIxxIRiRlVuijmZe1gbEoqa3bk8qMhHbjrgt40qqMhfiIiFSmsbyQws+FmtszMVprZ2FKuNzN7Onh9qpkNDOV+9+UVMG5aGldOnkexw99vGsojl/VXSYiIhEHYtijMrDrwLHAOkA3MN7MZ7p5ZYrHzge7Bj6HAn4Ofjyh7Vy5nPD6HXbn53HRKZ35zbk/q1tL4DRGRcAnnrqchwEp3zwIwszeBEUDJohgBvObuDswzs8Zm1sbdNx3pTnflFlA3J5+HL0viR0MSwxhfREQgvEXRDlhf4nI2/7u1UNoy7YD/KgozGw2MBqhWtxEbX/mlX/Ps7o1X7d+xucJTVy3Nge2RDhEltC6+o3XxHa2L7/Qs7w3DWRSlvXnBy7EM7j4ZmAxgZgsO5u5JPvZ4VZ+ZLXB3rQu0LkrSuviO1sV3zGxBeW8bzoPZ2UCHEpfbAxvLsYyIiERQOItiPtDdzDqbWS3gSmDGYcvMAK4NvvrpBGBPWccnRESk8oVt15O7F5rZbcAsoDrwkrtnmNktwesnAe8BFwArgVzghhDuenKYIldFWhff0br4jtbFd7QuvlPudWGBFxyJiIiUTmfuERGRMqkoRESkTFFbFOEa/1EVhbAurg6ug1Qz+9zMjotEzspwtHVRYrnBZlZkZpdXZr7KFMq6MLMzzGyRmWWY2SeVnbGyhPA7kmBm75jZ4uC6COV4aJVjZi+Z2VYzSz/C9eV73nT3qPsgcPB7FdAFqAUsBvoctswFwPsE3otxAvBlpHNHcF2cBDQJfn1+PK+LEst9RODFEpdHOncE/180JjAJITF4uWWkc0dwXdwNPBr8ugWwE6gV6exhWBenAQOB9CNcX67nzWjdovh2/Ie75wOHxn+U9O34D3efBzQ2szaVHbQSHHVduPvn7r4reHEegfejxKJQ/l8A/AJIAbZWZrhKFsq6uAqY6u7rANw9VtdHKOvCgYYWOItZAwJFUVi5McPP3ecS+NmOpFzPm9FaFEca7fF9l4kF3/fn/AmBvxhi0VHXhZm1A0YCkyoxVySE8v+iB9DEzOaY2UIzu7bS0lWuUNbFM0BvAm/oTQN+6e7FlRMvqpTreTNaz0dRYeM/YkDIP6eZDSNQFKeENVHkhLIungTGuHtRjJ8CN5R1UQMYBJwF1AW+MLN57r483OEqWSjr4jxgEXAm0BX4l5l96u57w5wt2pTreTNai0LjP74T0s9pZv2BF4Dz3X1HJWWrbKGsi2TgzWBJNAcuMLNCd59eKQkrT6i/I9vdPQfIMbO5wHFArBVFKOviBmCiB3bUrzSz1UAv4KvKiRg1yvW8Ga27njT+4ztHXRdmlghMBa6Jwb8WSzrqunD3zu7eyd07AVOAn8dgSUBovyNvA6eaWQ0zq0dgevOSSs5ZGUJZF+sIbFlhZq0ITFLNqtSU0aFcz5tRuUXh4Rv/UeWEuC7uA5oBzwX/ki70GJyYGeK6iAuhrAt3X2JmHwCpQDHwgruX+rLJqizE/xcPAq+YWRqB3S9j3D3mxo+b2RvAGUBzM8sG7gdqwrE9b2qEh4iIlCladz2JiEiUUFGIiEiZVBQiIlImFYWIiJRJRSEiImVSUUhUCk5+XVTio1MZy+6vgMd7xcxWBx/razM7sRz38YKZ9Ql+ffdh131+rBmD93NovaQHp6E2PsryA8zsgop4bIlfenmsRCUz2+/uDSp62TLu4xXgXXefYmbnAk+4e/9juL9jznS0+zWzV4Hl7v5QGctfDyS7+20VnUXih7YopEowswZm9u/gX/tpZvY/U2PNrI2ZzS3xF/epwe+fa2ZfBG/7lpkd7Ql8LtAteNtfB+8r3cx+FfxefTObGTy3QbqZXRH8/hwzSzaziUDdYI7Xg9ftD37+R8m/8INbMqPMrLqZPW5m8y1wnoCbQ1gtXxAc6GZmQyxwLpJvgp97Bt+l/ABwRTDLFcHsLwUf55vS1qPI/4j0/HR96KO0D6CIwBC3RcA0AlMEGgWva07gnaWHtoj3Bz//BhgX/Lo60DC47FygfvD7Y4D7Snm8VwieuwL4AfAlgYF6aUB9AqOpM4DjgVHA8yVumxD8PIfAX+/fZiqxzKGMI4FXg1/XIjDJsy4wGrgn+P3awAKgcyk595f4+d4ChgcvNwJqBL8+G0gJfn098EyJ2z8M/Dj4dWMCc5/qR/rfWx/R/RGVIzxEgAPuPuDQBTOrCTxsZqcRGEfRDmgFbC5xm/nAS8Flp7v7IjM7HegDfBYcb1KLwF/ipXnczO4BthGYwnsWMM0DQ/Uws6nAqcAHwBNm9iiB3VWffo+f633gaTOrDQwH5rr7geDurv723Rn5EoDuwOrDbl/XzBYBnYCFwL9KLP+qmXUnMA205hEe/1zgEjP7bfByHSCR2JwBJRVERSFVxdUEzkw2yN0LzGwNgSe5b7n73GCRXAj81cweB3YB/3L3H4XwGHe4+5RDF8zs7NIWcvflZjaIwMycR8zsQ3d/IJQfwt3zzGwOgbHXVwBvHHo44BfuPusod3HA3QeYWQLwLnAr8DSBWUYfu/vI4IH/OUe4vQGj3H1ZKHlFQMcopOpIALYGS2IY0PHwBcysY3CZ54EXCZwSch5wspkdOuZQz8x6hPiYc4FLg7epT2C30adm1hbIdfe/AU8EH+dwBcEtm9K8SWAY26kEBtkR/PyzQ7cxsx7BxyyVu+8Bbgd+G7xNArAhePX1JRbdR2AX3CGzgF9YcPPKzI4/0mOIHKKikKridSDZzBYQ2LpYWsoyZwCLzOwbAscRnnL3bQSeON8ws1QCxdErlAd0968JHLv4isAxixfc/RsgCfgquAtoHDChlJtPBlIPHcw+zIcEzm082wOn7oTAuUQyga/NLB34C0fZ4g9mWUxgrPZjBLZuPiNw/OKQj4E+hw5mE9jyqBnMlh68LFImvTxWRETKpC0KEREpk4pCRETKpKIQEZEyqShERKRMKgoRESmTikJERMqkohARkTL9P6lSZ97EyzfxAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ytest, yresult = [], []\n",
    "for i in range(len(Y_test)):\n",
    "    ytest.append(Y_test[i][0])\n",
    "    yresult.append(Y_result[i][0])\n",
    "    \n",
    "fpr, tpr, thresholds = roc_curve(ytest, yresult)\n",
    "\n",
    "def plot_roc_curve(fpr,tpr):\n",
    "    plt.plot(fpr, tpr, marker='.')\n",
    "    plt.axis([0,1,0,1])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.show()\n",
    "plot_roc_curve(fpr,tpr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
